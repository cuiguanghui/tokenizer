/***********************************************************************
 * AUTHOR: KITE <KITE>
 *   FILE: Tokenizer.cpp stub file
 *   DATE: Tue Sep 16 15:54:32 2014
 *  DESCR:
 ***********************************************************************/
#include "Tokenizer.h"
#include <iostream>
using namespace std;

/*
 *  Method: Tokenizer::Tokenizer
 *  Params:
 * Effects:
 */
Tokenizer::Tokenizer()
{
    cerr << "Tokenizer::Tokenizer()" << endl;
}


/*
 *  Method: Tokenizer::Tokenizer
 *  Params: const std::string &str, const std::string &delimiter
 * Effects:
 */
Tokenizer::Tokenizer(const std::string &str, const std::string &delimiter)
{
    cerr << "Tokenizer::Tokenizer()" << endl;
}


/*
 *  Method: Tokenizer::~Tokenizer
 *  Params:
 * Effects:
 */
Tokenizer::~Tokenizer()
{
    cerr << "Tokenizer::~Tokenizer()" << endl;
}


/*
 *  Method: Tokenizer::set
 *  Params: const std::string &str, const std::string &delimiter
 * Returns: void
 * Effects:
 */
void
Tokenizer::set(const std::string &str, const std::string &delimiter)
{
    cerr << "Tokenizer::set()" << endl;
}


/*
 *  Method: Tokenizer::setString
 *  Params: const std::string &str
 * Returns: void
 * Effects:
 */
void
Tokenizer::setString(const std::string &str)
{
    cerr << "Tokenizer::setString()" << endl;
}


/*
 *  Method: Tokenizer::setDelimiter
 *  Params: const std::string &delimiter
 * Returns: void
 * Effects:
 */
void
Tokenizer::setDelimiter(const std::string &delimiter)
{
    cerr << "Tokenizer::setDelimiter()" << endl;
}


/*
 *  Method: Tokenizer::next
 *  Params:
 * Returns: std::string
 * Effects:
 */
std::string
Tokenizer::next()
{
    std::string dummy;

    cerr << "Tokenizer::next()" << endl;
    return dummy;
}


/*
 *  Method: Tokenizer::split
 *  Params:
 * Returns: std::vector<std::string>
 * Effects:
 */
std::vector<std::string>
Tokenizer::split()
{
    std::vector<std::string> dummy;

    cerr << "Tokenizer::split()" << endl;
    return dummy;
}


/*
 *  Method: Tokenizer::sort_tokens
 *  Params:
 * Returns: std::vector<std::string>
 * Effects:
 */
std::vector<std::string> Tokenizer::sort_tokens()
{
    std::vector<std::string> dummy;

    cerr << "Tokenizer::sort_tokens()" << endl;
    return dummy;
}


/*
 *  Method: Tokenizer::set_of_tokens
 *  Params:
 * Returns: std::set<std::string>
 * Effects:
 */
std::set<std::string>
Tokenizer::set_of_tokens()
{
    std::set<std::string> dummy;

    cerr << "Tokenizer::set_of_tokens()" << endl;
    return dummy;
}


/*
 *  Method: Tokenizer::longest_token
 *  Params:
 * Returns: std::string
 * Effects:
 */
std::string
Tokenizer::longest_token()
{
    std::string dummy;

    cerr << "Tokenizer::longest_token()" << endl;
    return dummy;
}


/*
 *  Method: Tokenizer::find_token
 *  Params: unsigned int n
 * Returns: std::string
 * Effects:
 */
std::string
Tokenizer::find_token(unsigned int n)
{
    std::string dummy;

    cerr << "Tokenizer::find_token()" << endl;
    return dummy;
}


/*
 *  Method: Tokenizer::check_for_duplicates
 *  Params:
 * Returns: bool
 * Effects:
 */
bool
Tokenizer::check_for_duplicates()
{
    bool dummy;

    cerr << "Tokenizer::check_for_duplicates()" << endl;
    return dummy;
}


/*
 *  Method: Tokenizer::skipDelimiter
 *  Params:
 * Returns: void
 * Effects:
 */
void
Tokenizer::skipDelimiter()
{
    cerr << "Tokenizer::skipDelimiter()" << endl;
}


/*
 *  Method: Tokenizer::isDelimiter
 *  Params: char c
 * Returns: bool
 * Effects:
 */
bool
Tokenizer::isDelimiter(char c)
{
    bool dummy;

    cerr << "Tokenizer::isDelimiter()" << endl;
    return dummy;
}


